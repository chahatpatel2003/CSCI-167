{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5qdnLkJ7QzIDcM7Sq3BMT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chahatpatel2003/CSCI-167/blob/main/notebook_12_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, set_seed\n",
        "import torch, numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "np.random.seed(1)\n",
        "print(\"Number of tokens in dictionary =\", tokenizer.vocab_size)\n",
        "for _ in range(20):\n",
        "  idx = np.random.randint(tokenizer.vocab_size)\n",
        "  print(\"Token:\", idx, tokenizer.decode(torch.tensor(idx), skip_special_tokens=True))\n",
        "\n",
        "def sample_next_token(input_tokens, model, tokenizer):\n",
        "  outputs = model(input_ids=input_tokens['input_ids'], attention_mask=input_tokens['attention_mask'])\n",
        "  probs = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "  next_id = int(np.random.choice(len(probs), p=probs))\n",
        "  out = input_tokens\n",
        "  out[\"input_ids\"] = torch.cat((out['input_ids'], torch.tensor([[next_id]], dtype=torch.long)), dim=1)\n",
        "  out['attention_mask'] = torch.cat((out['attention_mask'], torch.tensor([[1]])), dim=1)\n",
        "  out['last_token_prob'] = float(probs[next_id])\n",
        "  return out\n",
        "\n",
        "def get_best_next_token(input_tokens, model, tokenizer):\n",
        "  outputs = model(input_ids=input_tokens['input_ids'], attention_mask=input_tokens['attention_mask'])\n",
        "  probs = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "  next_id = int(np.argmax(probs))\n",
        "  out = input_tokens\n",
        "  out[\"input_ids\"] = torch.cat((out['input_ids'], torch.tensor([[next_id]], dtype=torch.long)), dim=1)\n",
        "  out['attention_mask'] = torch.cat((out['attention_mask'], torch.tensor([[1]])), dim=1)\n",
        "  out['last_token_prob'] = float(probs[next_id])\n",
        "  return out\n",
        "\n",
        "def get_top_k_token(input_tokens, model, tokenizer, k=20):\n",
        "  outputs = model(input_ids=input_tokens['input_ids'], attention_mask=input_tokens['attention_mask'])\n",
        "  probs = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "  sorted_desc = np.sort(probs)[::-1]\n",
        "  k = max(1, min(k, len(sorted_desc)))\n",
        "  thresh = sorted_desc[k-1]\n",
        "  mask = probs >= thresh\n",
        "  probs = probs * mask\n",
        "  probs = probs / probs.sum()\n",
        "  next_id = int(np.random.choice(len(probs), p=probs))\n",
        "  out = input_tokens\n",
        "  out[\"input_ids\"] = torch.cat((out['input_ids'], torch.tensor([[next_id]], dtype=torch.long)), dim=1)\n",
        "  out['attention_mask'] = torch.cat((out['attention_mask'], torch.tensor([[1]])), dim=1)\n",
        "  out['last_token_prob'] = float(probs[next_id])\n",
        "  return out\n",
        "\n",
        "def get_nucleus_sampling_token(input_tokens, model, tokenizer, thresh=0.25):\n",
        "  outputs = model(input_ids=input_tokens['input_ids'], attention_mask=input_tokens['attention_mask'])\n",
        "  probs = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "  sorted_desc = np.sort(probs)[::-1]\n",
        "  csum = np.cumsum(sorted_desc)\n",
        "  idx = int(np.argmax(csum > thresh))\n",
        "  print(\"Choosing from %d tokens\" % (idx+1))\n",
        "  cutoff = sorted_desc[idx]\n",
        "  mask = probs >= cutoff\n",
        "  probs = probs * mask\n",
        "  probs = probs / probs.sum()\n",
        "  next_id = int(np.random.choice(len(probs), p=probs))\n",
        "  out = input_tokens\n",
        "  out[\"input_ids\"] = torch.cat((out['input_ids'], torch.tensor([[next_id]], dtype=torch.long)), dim=1)\n",
        "  out['attention_mask'] = torch.cat((out['attention_mask'], torch.tensor([[1]])), dim=1)\n",
        "  out['last_token_prob'] = float(probs[next_id])\n",
        "  return out\n",
        "\n",
        "def get_kth_most_likely_token(input_tokens, model, tokenizer, k):\n",
        "  outputs = model(input_ids=input_tokens['input_ids'], attention_mask=input_tokens['attention_mask'])\n",
        "  probs = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "  order = np.argsort(probs)[::-1]\n",
        "  k = min(max(0, k), len(order)-1)\n",
        "  next_id = int(order[k])\n",
        "  out = input_tokens\n",
        "  out[\"input_ids\"] = torch.cat((out['input_ids'], torch.tensor([[next_id]], dtype=torch.long)), dim=1)\n",
        "  out['attention_mask'] = torch.cat((out['attention_mask'], torch.tensor([[1]])), dim=1)\n",
        "  p = float(probs[next_id])\n",
        "  out['last_token_prob'] = p\n",
        "  out['log_prob'] = out['log_prob'] + np.log(p)\n",
        "  return out\n",
        "\n",
        "def print_beams(beams):\n",
        "  for i, b in enumerate(beams):\n",
        "    print(f\"Beam {i}, Prob {float(b['log_prob']):.3f}: \" + tokenizer.decode(b[\"input_ids\"][0], skip_special_tokens=True))\n",
        "  print('---')\n",
        "\n",
        "def do_beam_search(input_tokens_in, model, tokenizer, n_beam=5, beam_length=10):\n",
        "  seed_tok = dict(input_tokens_in)\n",
        "  seed_tok['log_prob'] = 0.0\n",
        "  beams = []\n",
        "  for c in range(n_beam):\n",
        "    b = dict(seed_tok)\n",
        "    b = get_kth_most_likely_token(b, model, tokenizer, c)\n",
        "    beams.append(b)\n",
        "  print_beams(beams)\n",
        "  for _ in range(beam_length-1):\n",
        "    exps, scores = [], []\n",
        "    for b in beams:\n",
        "      for c in range(n_beam):\n",
        "        nb = get_kth_most_likely_token(dict(b), model, tokenizer, c)\n",
        "        exps.append(nb)\n",
        "        scores.append(float(nb['log_prob']))\n",
        "    idx = np.argsort(-np.array(scores))\n",
        "    beams = [dict(exps[i]) for i in idx[:n_beam]]\n",
        "    print_beams(beams)\n",
        "  return beams[0]\n",
        "\n",
        "set_seed(0)\n",
        "t = tokenizer(\"The best thing about Bath is\", return_tensors='pt')\n",
        "for _ in range(10):\n",
        "  t = sample_next_token(t, model, tokenizer)\n",
        "  print(tokenizer.decode(t[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n",
        "set_seed(0)\n",
        "t = tokenizer(\"The best thing about Bath is\", return_tensors='pt')\n",
        "for _ in range(10):\n",
        "  t = get_best_next_token(t, model, tokenizer)\n",
        "  print(tokenizer.decode(t[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n",
        "set_seed(0)\n",
        "t = tokenizer(\"The best thing about Bath is\", return_tensors='pt')\n",
        "for _ in range(10):\n",
        "  t = get_top_k_token(t, model, tokenizer, k=10)\n",
        "  print(tokenizer.decode(t[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n",
        "set_seed(0)\n",
        "t = tokenizer(\"The best thing about Bath is\", return_tensors='pt')\n",
        "for _ in range(10):\n",
        "  t = get_nucleus_sampling_token(t, model, tokenizer, thresh=0.2)\n",
        "  print(tokenizer.decode(t[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n",
        "set_seed(0)\n",
        "t = tokenizer(\"The best thing about Bath is\", return_tensors='pt'); t['log_prob'] = 0.0\n",
        "for _ in range(10):\n",
        "  t = get_kth_most_likely_token(t, model, tokenizer, k=1)\n",
        "  print(tokenizer.decode(t[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n",
        "t = tokenizer(\"The best thing about Bath is\", return_tensors='pt'); t['log_prob'] = 0.0\n",
        "for _ in range(10):\n",
        "  t = get_kth_most_likely_token(t, model, tokenizer, k=2000)\n",
        "  print(tokenizer.decode(t[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n",
        "set_seed(0)\n",
        "best = do_beam_search(tokenizer(\"The best thing about Bath is\", return_tensors='pt'), model, tokenizer, n_beam=5, beam_length=10)\n",
        "print(\"Beam search result:\")\n",
        "print(tokenizer.decode(best[\"input_ids\"][0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JKR09LzNTAI",
        "outputId": "df8f7ac8-e61a-4024-9e64-0eec684b632f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in dictionary = 50257\n",
            "Token: 33003  Mormons\n",
            "Token: 12172  cam\n",
            "Token: 5192  trig\n",
            "Token: 32511 ojure\n",
            "Token: 50057  gist\n",
            "Token: 43723  Petition\n",
            "Token: 7813  sin\n",
            "Token: 21440  Witness\n",
            "Token: 32912  Remy\n",
            "Token: 20609 isure\n",
            "Token: 49100  creeps\n",
            "Token: 7751  fasc\n",
            "Token: 43757  Alc\n",
            "Token: 31228  messenger\n",
            "Token: 36230  SYSTEM\n",
            "Token: 32025  precipitation\n",
            "Token: 21758  cores\n",
            "Token: 45413  Forestry\n",
            "Token: 35730  guru\n",
            "Token: 8444  Disc\n",
            "The best thing about Bath is that\n",
            "The best thing about Bath is that they\n",
            "The best thing about Bath is that they don\n",
            "The best thing about Bath is that they don't\n",
            "The best thing about Bath is that they don't even\n",
            "The best thing about Bath is that they don't even change\n",
            "The best thing about Bath is that they don't even change or\n",
            "The best thing about Bath is that they don't even change or shrink\n",
            "The best thing about Bath is that they don't even change or shrink anymore\n",
            "The best thing about Bath is that they don't even change or shrink anymore.\n",
            "The best thing about Bath is that\n",
            "The best thing about Bath is that it\n",
            "The best thing about Bath is that it's\n",
            "The best thing about Bath is that it's a\n",
            "The best thing about Bath is that it's a place\n",
            "The best thing about Bath is that it's a place where\n",
            "The best thing about Bath is that it's a place where you\n",
            "The best thing about Bath is that it's a place where you can\n",
            "The best thing about Bath is that it's a place where you can go\n",
            "The best thing about Bath is that it's a place where you can go to\n",
            "The best thing about Bath is that\n",
            "The best thing about Bath is that you\n",
            "The best thing about Bath is that you get\n",
            "The best thing about Bath is that you get to\n",
            "The best thing about Bath is that you get to see\n",
            "The best thing about Bath is that you get to see all\n",
            "The best thing about Bath is that you get to see all the\n",
            "The best thing about Bath is that you get to see all the beautiful\n",
            "The best thing about Bath is that you get to see all the beautiful faces\n",
            "The best thing about Bath is that you get to see all the beautiful faces of\n",
            "Choosing from 1 tokens\n",
            "The best thing about Bath is that\n",
            "Choosing from 1 tokens\n",
            "The best thing about Bath is that it\n",
            "Choosing from 1 tokens\n",
            "The best thing about Bath is that it's\n",
            "Choosing from 3 tokens\n",
            "The best thing about Bath is that it's not\n",
            "Choosing from 2 tokens\n",
            "The best thing about Bath is that it's not a\n",
            "Choosing from 26 tokens\n",
            "The best thing about Bath is that it's not a city\n",
            "Choosing from 3 tokens\n",
            "The best thing about Bath is that it's not a city that\n",
            "Choosing from 2 tokens\n",
            "The best thing about Bath is that it's not a city that has\n",
            "Choosing from 2 tokens\n",
            "The best thing about Bath is that it's not a city that has been\n",
            "Choosing from 12 tokens\n",
            "The best thing about Bath is that it's not a city that has been around\n",
            "The best thing about Bath is the\n",
            "The best thing about Bath is the way\n",
            "The best thing about Bath is the way you\n",
            "The best thing about Bath is the way you get\n",
            "The best thing about Bath is the way you get the\n",
            "The best thing about Bath is the way you get the most\n",
            "The best thing about Bath is the way you get the most bang\n",
            "The best thing about Bath is the way you get the most bang out\n",
            "The best thing about Bath is the way you get the most bang outta\n",
            "The best thing about Bath is the way you get the most bang outta the\n",
            "The best thing about Bath is mixed\n",
            "The best thing about Bath is mixed profits\n",
            "The best thing about Bath is mixed profits partnerships\n",
            "The best thing about Bath is mixed profits partnerships»\n",
            "The best thing about Bath is mixed profits partnerships» buy\n",
            "The best thing about Bath is mixed profits partnerships» buy generic\n",
            "The best thing about Bath is mixed profits partnerships» buy generic+\n",
            "The best thing about Bath is mixed profits partnerships» buy generic+ Honda\n",
            "The best thing about Bath is mixed profits partnerships» buy generic+ Honda throttle\n",
            "The best thing about Bath is mixed profits partnerships» buy generic+ Honda throttlecont\n",
            "Beam 0, Prob -0.727: The best thing about Bath is that\n",
            "Beam 1, Prob -2.161: The best thing about Bath is the\n",
            "Beam 2, Prob -3.177: The best thing about Bath is it\n",
            "Beam 3, Prob -3.468: The best thing about Bath is how\n",
            "Beam 4, Prob -3.536: The best thing about Bath is you\n",
            "---\n",
            "Beam 0, Prob -1.899: The best thing about Bath is that it\n",
            "Beam 1, Prob -2.381: The best thing about Bath is that you\n",
            "Beam 2, Prob -3.557: The best thing about Bath is that they\n",
            "Beam 3, Prob -3.561: The best thing about Bath is that we\n",
            "Beam 4, Prob -3.727: The best thing about Bath is that the\n",
            "---\n",
            "Beam 0, Prob -2.740: The best thing about Bath is that it's\n",
            "Beam 1, Prob -3.264: The best thing about Bath is that you can\n",
            "Beam 2, Prob -4.079: The best thing about Bath is that it is\n",
            "Beam 3, Prob -4.372: The best thing about Bath is that you don\n",
            "Beam 4, Prob -4.499: The best thing about Bath is that you get\n",
            "---\n",
            "Beam 0, Prob -4.373: The best thing about Bath is that you don't\n",
            "Beam 1, Prob -4.938: The best thing about Bath is that it's a\n",
            "Beam 2, Prob -5.252: The best thing about Bath is that you get to\n",
            "Beam 3, Prob -5.331: The best thing about Bath is that it's not\n",
            "Beam 4, Prob -6.091: The best thing about Bath is that it's so\n",
            "---\n",
            "Beam 0, Prob -4.844: The best thing about Bath is that you don't have\n",
            "Beam 1, Prob -6.420: The best thing about Bath is that you don't need\n",
            "Beam 2, Prob -7.313: The best thing about Bath is that it's not a\n",
            "Beam 3, Prob -7.315: The best thing about Bath is that you get to see\n",
            "Beam 4, Prob -7.509: The best thing about Bath is that it's not just\n",
            "---\n",
            "Beam 0, Prob -4.878: The best thing about Bath is that you don't have to\n",
            "Beam 1, Prob -6.833: The best thing about Bath is that you don't need to\n",
            "Beam 2, Prob -8.791: The best thing about Bath is that you don't need a\n",
            "Beam 3, Prob -8.888: The best thing about Bath is that you get to see the\n",
            "Beam 4, Prob -8.923: The best thing about Bath is that it's not just a\n",
            "---\n",
            "Beam 0, Prob -6.959: The best thing about Bath is that you don't have to worry\n",
            "Beam 1, Prob -7.526: The best thing about Bath is that you don't have to be\n",
            "Beam 2, Prob -7.899: The best thing about Bath is that you don't have to go\n",
            "Beam 3, Prob -8.183: The best thing about Bath is that you don't have to pay\n",
            "Beam 4, Prob -8.309: The best thing about Bath is that you don't have to do\n",
            "---\n",
            "Beam 0, Prob -7.019: The best thing about Bath is that you don't have to worry about\n",
            "Beam 1, Prob -9.119: The best thing about Bath is that you don't have to be a\n",
            "Beam 2, Prob -9.269: The best thing about Bath is that you don't have to go to\n",
            "Beam 3, Prob -9.539: The best thing about Bath is that you don't have to do anything\n",
            "Beam 4, Prob -9.577: The best thing about Bath is that you don't have to pay for\n",
            "---\n",
            "Beam 0, Prob -9.867: The best thing about Bath is that you don't have to worry about your\n",
            "Beam 1, Prob -9.905: The best thing about Bath is that you don't have to worry about the\n",
            "Beam 2, Prob -9.968: The best thing about Bath is that you don't have to worry about getting\n",
            "Beam 3, Prob -10.217: The best thing about Bath is that you don't have to worry about it\n",
            "Beam 4, Prob -10.414: The best thing about Bath is that you don't have to worry about being\n",
            "---\n",
            "Beam 0, Prob -11.902: The best thing about Bath is that you don't have to worry about it.\n",
            "Beam 1, Prob -12.438: The best thing about Bath is that you don't have to worry about it being\n",
            "Beam 2, Prob -12.628: The best thing about Bath is that you don't have to worry about getting a\n",
            "Beam 3, Prob -12.713: The best thing about Bath is that you don't have to worry about getting caught\n",
            "Beam 4, Prob -13.125: The best thing about Bath is that you don't have to worry about getting your\n",
            "---\n",
            "Beam search result:\n",
            "The best thing about Bath is that you don't have to worry about it.\n"
          ]
        }
      ]
    }
  ]
}