{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdlqLJbtkVvt9PoTxabRPj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chahatpatel2003/CSCI-167/blob/main/notebook_7_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFjQQ67RJHAg",
        "outputId": "8ca6952a-8907-4d27-c3c4-f78c14645358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Forward pass with K=50, D=80, sigma_sq_omega=1.000000 ===\n",
            "Layer  1, std of hidden units = 0.656872\n",
            "Layer 10, std of hidden units = 8984991.951712\n",
            "Layer 20, std of hidden units = 571669882459492.125000\n",
            "Layer 30, std of hidden units = 123600525236285774757888.000000\n",
            "Layer 40, std of hidden units = 3871517592822056449697747304448.000000\n",
            "Layer 50, std of hidden units = 263828723966224442553385425202470453248.000000\n",
            "Summary: first=0.656872, median=37329899293413752832.000000, last=263828723966224442553385425202470453248.000000\n",
            "\n",
            "=== Forward pass with K=50, D=80, sigma_sq_omega=0.100000 ===\n",
            "Layer  1, std of hidden units = 0.207721\n",
            "Layer 10, std of hidden units = 89.849920\n",
            "Layer 20, std of hidden units = 57166.988246\n",
            "Layer 30, std of hidden units = 123600525.236286\n",
            "Layer 40, std of hidden units = 38715175928.220612\n",
            "Layer 50, std of hidden units = 26382872396622.488281\n",
            "Summary: first=0.207721, median=4702168.299271, last=26382872396622.488281\n",
            "\n",
            "=== Forward pass with K=50, D=80, sigma_sq_omega=0.010000 ===\n",
            "Layer  1, std of hidden units = 0.065687\n",
            "Layer 10, std of hidden units = 0.000898\n",
            "Layer 20, std of hidden units = 0.000006\n",
            "Layer 30, std of hidden units = 0.000000\n",
            "Layer 40, std of hidden units = 0.000000\n",
            "Layer 50, std of hidden units = 0.000000\n",
            "Summary: first=0.065687, median=0.000001, last=0.000000\n",
            "\n",
            "=== Forward pass with K=50, D=80, sigma_sq_omega=0.025000 ===\n",
            "Layer  1, std of hidden units = 0.103861\n",
            "Layer 10, std of hidden units = 0.087744\n",
            "Layer 20, std of hidden units = 0.054519\n",
            "Layer 30, std of hidden units = 0.115112\n",
            "Layer 40, std of hidden units = 0.035211\n",
            "Layer 50, std of hidden units = 0.023433\n",
            "Summary: first=0.103861, median=0.064355, last=0.023433\n",
            "\n",
            "=== Backward pass with K=50, D=80, sigma_sq_omega=1.000000 ===\n",
            "Layer  1, std of dl_df = 62167539263442482966241561068612776851017214058151540934595180625969593450496.000000\n",
            "Layer 10, std of dl_df = 5758314875657004552173296077946487921267519704498098690458800778903552.000000\n",
            "Layer 20, std of dl_df = 64645790637532538990614364512964163716565911808657524688683008.000000\n",
            "Layer 30, std of dl_df = 699231444888999524063085153063732108964631299221356544.000000\n",
            "Layer 40, std of dl_df = 11665171773131790991698603611384625271500963840.000000\n",
            "Layer 49, std of dl_df = 942019461296379692752815835126641459200.000000\n",
            "Summary: first=62167539263442482966241561068612776851017214058151540934595180625969593450496.000000, median=5968069596204989994509641872736976468603046217167761571840.000000, last=942019461296379692752815835126641459200.000000\n",
            "\n",
            "=== Backward pass with K=50, D=80, sigma_sq_omega=0.100000 ===\n",
            "Layer  1, std of dl_df = 621675392634426172666544128.000000\n",
            "Layer 10, std of dl_df = 1820939049150543715893248.000000\n",
            "Layer 20, std of dl_df = 2044279395569915658240.000000\n",
            "Layer 30, std of dl_df = 2211163977459744000.000000\n",
            "Layer 40, std of dl_df = 3688851210020147.500000\n",
            "Layer 49, std of dl_df = 9420194612963.804688\n",
            "Summary: first=621675392634426172666544128.000000, median=59680695962049986560.000000, last=9420194612963.804688\n",
            "\n",
            "=== Backward pass with K=50, D=80, sigma_sq_omega=0.010000 ===\n",
            "Layer  1, std of dl_df = 0.000000\n",
            "Layer 10, std of dl_df = 0.000000\n",
            "Layer 20, std of dl_df = 0.000000\n",
            "Layer 30, std of dl_df = 0.000000\n",
            "Layer 40, std of dl_df = 0.000000\n",
            "Layer 49, std of dl_df = 0.000000\n",
            "Summary: first=0.000000, median=0.000000, last=0.000000\n",
            "\n",
            "=== Backward pass with K=50, D=80, sigma_sq_omega=0.025000 ===\n",
            "Layer  1, std of dl_df = 0.000490\n",
            "Layer 10, std of dl_df = 0.000735\n",
            "Layer 20, std of dl_df = 0.000845\n",
            "Layer 30, std of dl_df = 0.000936\n",
            "Layer 40, std of dl_df = 0.001600\n",
            "Layer 49, std of dl_df = 0.002092\n",
            "Summary: first=0.000490, median=0.000870, last=0.002092\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def init_params(K, D, sigma_sq_omega):\n",
        "    np.random.seed(0)\n",
        "    D_i = 1\n",
        "    D_o = 1\n",
        "    all_weights = [None] * (K+1)\n",
        "    all_biases = [None] * (K+1)\n",
        "    all_weights[0] = np.random.normal(size=(D, D_i)) * np.sqrt(sigma_sq_omega)\n",
        "    all_biases[0] = np.zeros((D, 1))\n",
        "    for layer in range(1, K):\n",
        "        all_weights[layer] = np.random.normal(size=(D, D)) * np.sqrt(sigma_sq_omega)\n",
        "        all_biases[layer] = np.zeros((D, 1))\n",
        "    all_weights[K] = np.random.normal(size=(D_o, D)) * np.sqrt(sigma_sq_omega)\n",
        "    all_biases[K] = np.zeros((D_o, 1))\n",
        "    return all_weights, all_biases\n",
        "\n",
        "def ReLU(preactivation):\n",
        "    return preactivation.clip(0.0)\n",
        "\n",
        "def compute_network_output(net_input, all_weights, all_biases):\n",
        "    K = len(all_weights) - 1\n",
        "    all_f = [None] * (K+1)\n",
        "    all_h = [None] * (K+1)\n",
        "    all_h[0] = net_input\n",
        "    for layer in range(K):\n",
        "        all_f[layer] = all_biases[layer] + np.matmul(all_weights[layer], all_h[layer])\n",
        "        all_h[layer+1] = ReLU(all_f[layer])\n",
        "    all_f[K] = all_biases[K] + np.matmul(all_weights[K], all_h[K])\n",
        "    net_output = all_f[K]\n",
        "    return net_output, all_f, all_h\n",
        "\n",
        "def run_forward_experiment(K=50, D=80, sigma_list=(1.0, 0.1, 0.01, 2.0/80)):\n",
        "    n_data = 1000\n",
        "    data_in = np.random.normal(size=(1, n_data))\n",
        "    for sigma_sq_omega in sigma_list:\n",
        "        print(f\"\\n=== Forward pass with K={K}, D={D}, sigma_sq_omega={sigma_sq_omega:.6f} ===\")\n",
        "        all_weights, all_biases = init_params(K, D, sigma_sq_omega)\n",
        "        net_output, all_f, all_h = compute_network_output(data_in, all_weights, all_biases)\n",
        "        stds = []\n",
        "        for layer in range(1, K+1):\n",
        "            layer_std = float(np.std(all_h[layer]))\n",
        "            stds.append(layer_std)\n",
        "            if layer % 10 == 0 or layer == 1 or layer == K:\n",
        "                print(f\"Layer {layer:2d}, std of hidden units = {layer_std:0.6f}\")\n",
        "        print(f\"Summary: first={stds[0]:.6f}, median={np.median(stds):.6f}, last={stds[-1]:.6f}\")\n",
        "\n",
        "run_forward_experiment()\n",
        "\n",
        "def least_squares_loss(net_output, y):\n",
        "    return np.sum((net_output - y) * (net_output - y))\n",
        "\n",
        "def d_loss_d_output(net_output, y):\n",
        "    return 2*(net_output - y)\n",
        "\n",
        "def indicator_function(x):\n",
        "    x_in = np.array(x)\n",
        "    x_in[x_in >= 0] = 1\n",
        "    x_in[x_in < 0]  = 0\n",
        "    return x_in\n",
        "\n",
        "def backward_pass(all_weights, all_biases, all_f, all_h, y):\n",
        "    K = len(all_weights) - 1\n",
        "    all_dl_dweights = [None] * (K+1)\n",
        "    all_dl_dbiases  = [None] * (K+1)\n",
        "    all_dl_df       = [None] * (K+1)\n",
        "    all_dl_dh       = [None] * (K+1)\n",
        "    all_dl_df[K] = np.array(d_loss_d_output(all_f[K], y))\n",
        "    for layer in range(K, -1, -1):\n",
        "        all_dl_dbiases[layer]  = np.array(all_dl_df[layer])\n",
        "        all_dl_dweights[layer] = np.matmul(all_dl_df[layer], all_h[layer].T)\n",
        "        all_dl_dh[layer]       = np.matmul(all_weights[layer].T, all_dl_df[layer])\n",
        "        if layer > 0:\n",
        "            all_dl_df[layer-1] = indicator_function(all_f[layer-1]) * all_dl_dh[layer]\n",
        "    return all_dl_dweights, all_dl_dbiases, all_dl_dh, all_dl_df\n",
        "\n",
        "def run_backward_experiment(K=50, D=80, sigma_list=(1.0, 0.1, 0.01, 2.0/80)):\n",
        "    n_data = 100\n",
        "    for sigma_sq_omega in sigma_list:\n",
        "        print(f\"\\n=== Backward pass with K={K}, D={D}, sigma_sq_omega={sigma_sq_omega:.6f} ===\")\n",
        "        all_weights, all_biases = init_params(K, D, sigma_sq_omega)\n",
        "        aggregate_dl_df = [None] * (K+1)\n",
        "        for layer in range(1, K):\n",
        "            aggregate_dl_df[layer] = np.zeros((D, n_data))\n",
        "        for c_data in range(n_data):\n",
        "            data_in = np.random.normal(size=(1,1))\n",
        "            y = np.zeros((1,1))\n",
        "            net_output, all_f, all_h = compute_network_output(data_in, all_weights, all_biases)\n",
        "            all_dl_dweights, all_dl_dbiases, all_dl_dh, all_dl_df = backward_pass(all_weights, all_biases, all_f, all_h, y)\n",
        "            for layer in range(1, K):\n",
        "                aggregate_dl_df[layer][:, c_data] = np.squeeze(all_dl_df[layer])\n",
        "        stds = []\n",
        "        for layer in range(1, K):\n",
        "            s = float(np.std(aggregate_dl_df[layer].ravel()))\n",
        "            stds.append(s)\n",
        "            if layer % 10 == 0 or layer == 1 or layer == K-1:\n",
        "                print(f\"Layer {layer:2d}, std of dl_df = {s:0.6f}\")\n",
        "        print(f\"Summary: first={stds[0]:.6f}, median={np.median(stds):.6f}, last={stds[-1]:.6f}\")\n",
        "\n",
        "run_backward_experiment()\n"
      ]
    }
  ]
}