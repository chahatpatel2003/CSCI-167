{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8xxXDWyblx5k0y/93dPxA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chahatpatel2003/CSCI-167/blob/main/notebook_12_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLp8gzHNJCMu",
        "outputId": "2d19457f-c825-4ba6-e58a-850483453277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent pair: ('s', 'e')\n",
            "Most frequent pair: ('e', '</w>')\n",
            "Most frequent pair: ('a', '</w>')\n",
            "Most frequent pair: ('se', 'e</w>')\n",
            "Most frequent pair: ('se', 'a</w>')\n",
            "Most frequent pair: ('t', '</w>')\n",
            "Most frequent pair: ('h', 'e</w>')\n",
            "Most frequent pair: ('t', 'o')\n",
            "Most frequent pair: ('to', '</w>')\n",
            "Most frequent pair: ('h', 'a')\n",
            "Most frequent pair: ('ha', 't</w>')\n",
            "Most frequent pair: ('c', 'o')\n",
            "Most frequent pair: ('co', 'u')\n",
            "Most frequent pair: ('cou', 'l')\n",
            "Most frequent pair: ('coul', 'd')\n",
            "Most frequent pair: ('could', '</w>')\n",
            "Most frequent pair: ('t', 'he</w>')\n",
            "Most frequent pair: ('s', 'a')\n",
            "Most frequent pair: ('sa', 'i')\n",
            "Most frequent pair: ('sai', 'l')\n",
            "Most frequent pair: ('sail', 'o')\n",
            "Most frequent pair: ('sailo', 'r')\n",
            "defaultdict(<class 'int'>, {'a</w>': 1, 'sailor': 1, '</w>': 6, 'w': 3, 'e': 3, 'n': 1, 't</w>': 2, 'to</w>': 2, 'sea</w>': 6, 'see</w>': 7, 'hat</w>': 2, 'he</w>': 2, 'could</w>': 2, 'b': 3, 'u': 2, 'a': 2, 'l': 3, 't': 2, 's': 1, 'the</w>': 2, 'o': 2, 'to': 1, 'm': 1, 'f': 1, 'd': 1, 'p': 1, 'e</w>': 1})\n",
            "27\n",
            "{'a</w>': 1, 'sailor </w>': 1, 'w e n t</w>': 1, 'to</w>': 2, 'sea</w>': 6, 'see</w>': 7, 'w hat</w>': 1, 'he</w>': 2, 'could</w>': 2, 'b u t</w>': 1, 'a l l </w>': 1, 't hat</w>': 1, 'w a s </w>': 1, 'the</w>': 2, 'b o t to m </w>': 1, 'o f </w>': 1, 'd e e p </w>': 1, 'b l u e</w>': 1}\n",
            "18\n",
            "['H', 'a', 'c', 'd', 'f', 'h', 'i', 'k', 'l', 'm', 'o', 'u', 'w', '</w>']\n",
            "14\n",
            "Most frequent pair: ('u', 'c')\n",
            "Most frequent pair: ('w', 'o')\n",
            "Most frequent pair: ('wo', 'o')\n",
            "Most frequent pair: ('woo', 'd')\n",
            "Most frequent pair: ('c', 'h')\n",
            "Most frequent pair: ('ch', 'uc')\n",
            "Most frequent pair: ('chuc', 'k')\n",
            "Most frequent pair: ('chuck', '</w>')\n",
            "Most frequent pair: ('wood', '</w>')\n",
            "Most frequent pair: ('c', 'o')\n",
            "Most frequent pair: ('co', 'u')\n",
            "Most frequent pair: ('cou', 'l')\n",
            "Most frequent pair: ('coul', 'd')\n",
            "Most frequent pair: ('could', '</w>')\n",
            "Most frequent pair: ('a', '</w>')\n",
            "Most frequent pair: ('wood', 'chuck</w>')\n",
            "Most frequent pair: ('H', 'o')\n",
            "Most frequent pair: ('Ho', 'w')\n",
            "Most frequent pair: ('How', '</w>')\n",
            "Most frequent pair: ('m', 'uc')\n",
            "Most frequent pair: ('muc', 'h')\n",
            "Most frequent pair: ('much', '</w>')\n",
            "Most frequent pair: ('i', 'f')\n",
            "Most frequent pair: ('if', '</w>')\n",
            "defaultdict(<class 'int'>, {'How</w>': 1, 'much</w>': 1, 'wood</w>': 2, 'could</w>': 2, 'a</w>': 2, 'woodchuck</w>': 2, 'chuck</w>': 2, 'if</w>': 1})\n",
            "8\n",
            "{'How</w>': 1, 'much</w>': 1, 'wood</w>': 2, 'could</w>': 2, 'a</w>': 2, 'woodchuck</w>': 2, 'chuck</w>': 2, 'if</w>': 1}\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "import re, collections\n",
        "\n",
        "text = \"a sailor went to sea sea sea \" + \\\n",
        "       \"to see what he could see see see \" + \\\n",
        "       \"but all that he could see see see \" + \\\n",
        "       \"was the bottom of the deep blue sea sea sea\"\n",
        "\n",
        "def initialize_vocabulary(text):\n",
        "  vocab = collections.defaultdict(int)\n",
        "  words = text.strip().split()\n",
        "  for word in words:\n",
        "      vocab[' '.join(list(word)) + ' </w>'] += 1\n",
        "  return vocab\n",
        "\n",
        "def get_tokens_and_frequencies(vocab):\n",
        "  tokens = collections.defaultdict(int)\n",
        "  for word, freq in vocab.items():\n",
        "      for token in word.split():\n",
        "          tokens[token] += freq\n",
        "  return tokens\n",
        "\n",
        "def get_pairs_and_counts(vocab):\n",
        "  pairs = collections.defaultdict(int)\n",
        "  for word, freq in vocab.items():\n",
        "      symbols = word.split()\n",
        "      for i in range(len(symbols) - 1):\n",
        "          pairs[(symbols[i], symbols[i+1])] += freq\n",
        "  return pairs\n",
        "\n",
        "def merge_pair_in_vocabulary(pair, vocab_in):\n",
        "  vocab_out = {}\n",
        "  bigram = re.escape(' '.join(pair))\n",
        "  p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
        "  for word in vocab_in:\n",
        "      word_out = p.sub(''.join(pair), word)\n",
        "      vocab_out[word_out] = vocab_in[word]\n",
        "  return vocab_out\n",
        "\n",
        "def tokenize(text, num_merges):\n",
        "  vocab = initialize_vocabulary(text)\n",
        "  for _ in range(num_merges):\n",
        "    tokens = get_tokens_and_frequencies(vocab)\n",
        "    pairs = get_pairs_and_counts(vocab)\n",
        "    if not pairs:\n",
        "      break\n",
        "    most_frequent_pair = max(pairs, key=pairs.get)\n",
        "    print(\"Most frequent pair:\", most_frequent_pair)\n",
        "    vocab = merge_pair_in_vocabulary(most_frequent_pair, vocab)\n",
        "  tokens = get_tokens_and_frequencies(vocab)\n",
        "  return tokens, vocab\n",
        "\n",
        "tokens, vocab = tokenize(text, num_merges=22)\n",
        "print(tokens)\n",
        "print(len(tokens))\n",
        "print(vocab)\n",
        "print(len(vocab))\n",
        "\n",
        "text2 = \"How much wood could a woodchuck chuck if a woodchuck could chuck wood\"\n",
        "\n",
        "def unique_initial_tokens(s):\n",
        "  chars = set(\"\".join(s.strip().split()))\n",
        "  return sorted(list(chars)) + [\"</w>\"]\n",
        "\n",
        "init_tok_list = unique_initial_tokens(text2)\n",
        "print(init_tok_list)\n",
        "print(len(init_tok_list))\n",
        "\n",
        "tokens2, vocab2 = tokenize(text2, num_merges=1000)\n",
        "print(tokens2)\n",
        "print(len(tokens2))\n",
        "print(vocab2)\n",
        "print(len(vocab2))\n"
      ]
    }
  ]
}